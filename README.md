# Zero-Shot Learning for Multimodal Nudging
Source code for the paper "Zero-Shot Recommendations with Pre-Trained Large Language Models for Multimodal Nudging".

![input_embedding](https://github.com/paxnea/wain23/assets/38059493/5235c3fc-5314-4b10-a6fe-f9b5f36f3839)

## File Structure
* directory `./content_generation/` contains files used for synthetic data generation
* directory `./data/` contains the generated dataset: user descriptions, messages, and image captions
* `main.ipynb` loads the generated data and computes recommendations via the proposed zero-shot approach

## Examples of Multimodal Recommendations
<img width="1325" alt="USER0" src="https://github.com/paxnea/wain23/assets/38059493/725613b7-58e1-4652-933c-fb4ae6035ced">
<img width="1325" alt="USER1" src="https://github.com/paxnea/wain23/assets/38059493/b0231306-aba1-45ec-9c02-24b44c227517">
<img width="1325" alt="USER2" src="https://github.com/paxnea/wain23/assets/38059493/6a816dc1-b77a-4f51-93b9-227ff4b0e543">
<img width="1325" alt="USER3" src="https://github.com/paxnea/wain23/assets/38059493/d7f6871d-9702-4534-8092-8d7a7399537d">
<img width="1325" alt="USER4" src="https://github.com/paxnea/wain23/assets/38059493/ede0113f-1620-41b3-b317-b6709b924a61">
